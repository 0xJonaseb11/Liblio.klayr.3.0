"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Storage = exports.encodeByteArray = void 0;
const lisk_db_1 = require("@liskhq/lisk-db");
const codec_1 = require("@klayr/codec");
const cryptography_1 = require("@klayr/cryptography");
const event_1 = require("../event");
const db_keys_1 = require("../db_keys");
const utils_1 = require("../utils");
const schema_1 = require("../schema");
const constants_1 = require("../constants");
const bytesArraySchema = {
    $id: '/klayrchain/bytesarray',
    type: 'object',
    required: ['list'],
    properties: {
        list: {
            type: 'array',
            fieldNumber: 1,
            items: {
                dataType: 'bytes',
            },
        },
    },
};
const decodeByteArray = (val) => {
    const decoded = codec_1.codec.decode(bytesArraySchema, val);
    return decoded.list;
};
const encodeByteArray = (val) => codec_1.codec.encode(bytesArraySchema, { list: val });
exports.encodeByteArray = encodeByteArray;
class Storage {
    constructor(db, options) {
        var _a, _b;
        this._db = db;
        this._keepEventsForHeights = (_a = options === null || options === void 0 ? void 0 : options.keepEventsForHeights) !== null && _a !== void 0 ? _a : constants_1.DEFAULT_KEEP_EVENTS_FOR_HEIGHTS;
        this._keepInclusionProofsForHeights =
            (_b = options === null || options === void 0 ? void 0 : options.keepInclusionProofsForHeights) !== null && _b !== void 0 ? _b : constants_1.DEFAULT_KEEP_INCLUSION_PROOFS_FOR_HEIGHTS;
    }
    async getBlockHeaderByID(id) {
        const block = await this._db.get((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_ID, id));
        return block;
    }
    async getBlockHeadersByIDs(arrayOfBlockIds) {
        const blocks = [];
        for (const id of arrayOfBlockIds) {
            try {
                const block = await this._db.get((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_ID, id));
                blocks.push(block);
            }
            catch (dbError) {
                if (dbError instanceof lisk_db_1.NotFoundError) {
                    continue;
                }
                throw dbError;
            }
        }
        return blocks;
    }
    async getBlockHeaderByHeight(height) {
        const id = await this._db.get((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_HEIGHT, (0, utils_1.uint32BE)(height)));
        return this.getBlockHeaderByID(id);
    }
    async getBlockHeadersByHeightBetween(fromHeight, toHeight) {
        const stream = this._db.createReadStream({
            gte: (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_HEIGHT, (0, utils_1.uint32BE)(fromHeight)),
            lte: (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_HEIGHT, (0, utils_1.uint32BE)(toHeight)),
            reverse: true,
        });
        const blockIDs = await new Promise((resolve, reject) => {
            const ids = [];
            stream
                .on('data', ({ value }) => {
                ids.push(value);
            })
                .on('error', error => {
                reject(error);
            })
                .on('end', () => {
                resolve(ids);
            });
        });
        return this.getBlockHeadersByIDs(blockIDs);
    }
    async getBlockHeadersWithHeights(heightList) {
        const blocks = [];
        for (const height of heightList) {
            try {
                const block = await this.getBlockHeaderByHeight(height);
                blocks.push(block);
            }
            catch (dbError) {
                if (dbError instanceof lisk_db_1.NotFoundError) {
                    continue;
                }
                throw dbError;
            }
        }
        return blocks;
    }
    async getLastBlockHeader() {
        const stream = this._db.createReadStream({
            gte: (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_HEIGHT, (0, utils_1.uint32BE)(0)),
            lte: (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_HEIGHT, (0, utils_1.uint32BE)(constants_1.MAX_UINT32)),
            reverse: true,
            limit: 1,
        });
        const [blockID] = await new Promise((resolve, reject) => {
            const ids = [];
            stream
                .on('data', ({ value }) => {
                ids.push(value);
            })
                .on('error', error => {
                reject(error);
            })
                .on('end', () => {
                resolve(ids);
            });
        });
        if (!blockID) {
            throw new lisk_db_1.NotFoundError('Last block header not found');
        }
        return this.getBlockHeaderByID(blockID);
    }
    async getBlockByID(id) {
        const blockHeader = await this.getBlockHeaderByID(id);
        const transactions = await this._getTransactions(id);
        const assets = await this._getBlockAssets(id);
        return {
            header: blockHeader,
            transactions,
            assets,
        };
    }
    async getBlocksByIDs(arrayOfBlockIds) {
        const blocks = [];
        for (const id of arrayOfBlockIds) {
            try {
                const block = await this.getBlockByID(id);
                blocks.push(block);
            }
            catch (dbError) {
                if (dbError instanceof lisk_db_1.NotFoundError) {
                    continue;
                }
                throw dbError;
            }
        }
        return blocks;
    }
    async getBlockByHeight(height) {
        const header = await this.getBlockHeaderByHeight(height);
        const blockID = cryptography_1.utils.hash(header);
        const transactions = await this._getTransactions(blockID);
        const assets = await this._getBlockAssets(blockID);
        return {
            header,
            transactions,
            assets,
        };
    }
    async getBlocksByHeightBetween(fromHeight, toHeight) {
        const headers = await this.getBlockHeadersByHeightBetween(fromHeight, toHeight);
        const blocks = [];
        for (const header of headers) {
            const blockID = cryptography_1.utils.hash(header);
            const transactions = await this._getTransactions(blockID);
            const assets = await this._getBlockAssets(blockID);
            blocks.push({ header, transactions, assets });
        }
        return blocks;
    }
    async getLastBlock() {
        const header = await this.getLastBlockHeader();
        const blockID = cryptography_1.utils.hash(header);
        const transactions = await this._getTransactions(blockID);
        const assets = await this._getBlockAssets(blockID);
        return {
            header,
            transactions,
            assets,
        };
    }
    async getEvents(height) {
        try {
            const eventsByte = await this._db.get((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCK_EVENTS, (0, utils_1.uint32BE)(height)));
            const events = decodeByteArray(eventsByte);
            return events.map(e => event_1.Event.fromBytes(e));
        }
        catch (error) {
            if (!(error instanceof lisk_db_1.NotFoundError)) {
                throw error;
            }
            return [];
        }
    }
    async setInclusionProofs(proof, height) {
        const proofBytes = codec_1.codec.encode(schema_1.inclusionProofSchema, proof);
        await this._db.set((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_INCLUSION_PROOFS, (0, utils_1.uint32BE)(height)), proofBytes);
    }
    async getInclusionProofs(height) {
        try {
            const proofBytes = await this._db.get((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_INCLUSION_PROOFS, (0, utils_1.uint32BE)(height)));
            return codec_1.codec.decode(schema_1.inclusionProofSchema, proofBytes);
        }
        catch (error) {
            if (!(error instanceof lisk_db_1.NotFoundError)) {
                throw error;
            }
            return {
                queries: [],
                siblingHashes: [],
            };
        }
    }
    async getTempBlocks() {
        const stream = this._db.createReadStream({
            gte: (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TEMPBLOCKS_HEIGHT, (0, utils_1.uint32BE)(0)),
            lte: (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TEMPBLOCKS_HEIGHT, (0, utils_1.uint32BE)(constants_1.MAX_UINT32)),
            reverse: true,
        });
        const tempBlocks = await new Promise((resolve, reject) => {
            const blocks = [];
            stream
                .on('data', ({ value }) => {
                blocks.push(value);
            })
                .on('error', error => {
                reject(error);
            })
                .on('end', () => {
                resolve(blocks);
            });
        });
        return tempBlocks;
    }
    async isTempBlockEmpty() {
        const stream = this._db.createReadStream({
            gte: (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TEMPBLOCKS_HEIGHT, (0, utils_1.uint32BE)(0)),
            lte: (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TEMPBLOCKS_HEIGHT, (0, utils_1.uint32BE)(constants_1.MAX_UINT32)),
            limit: 1,
        });
        const tempBlocks = await new Promise((resolve, reject) => {
            const blocks = [];
            stream
                .on('data', ({ value }) => {
                blocks.push(value);
            })
                .on('error', error => {
                reject(error);
            })
                .on('end', () => {
                resolve(blocks);
            });
        });
        return tempBlocks.length === 0;
    }
    async clearTempBlocks() {
        await this._clear((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TEMPBLOCKS_HEIGHT, (0, utils_1.uint32BE)(0)), (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TEMPBLOCKS_HEIGHT, (0, utils_1.uint32BE)(constants_1.MAX_UINT32)));
    }
    async isBlockPersisted(blockID) {
        return this._db.has((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_ID, blockID));
    }
    async getTransactionByID(id) {
        const transaction = await this._db.get((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TRANSACTIONS_ID, id));
        return transaction;
    }
    async getTransactionsByIDs(arrayOfTransactionIds) {
        const transactions = [];
        for (const id of arrayOfTransactionIds) {
            try {
                const transaction = await this.getTransactionByID(id);
                transactions.push(transaction);
            }
            catch (dbError) {
                if (dbError instanceof lisk_db_1.NotFoundError) {
                    continue;
                }
                throw dbError;
            }
        }
        return transactions;
    }
    async isTransactionPersisted(transactionId) {
        return this._db.has((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TRANSACTIONS_ID, transactionId));
    }
    async getFinalizedHeight() {
        const finalizedHeightBytes = await this._db.get(db_keys_1.DB_KEY_FINALIZED_HEIGHT);
        return finalizedHeightBytes.readUInt32BE(0);
    }
    async saveBlock(id, height, finalizedHeight, header, transactions, events, assets, state, removeFromTemp = false) {
        const heightBuf = (0, utils_1.uint32BE)(height);
        const { batch, diff } = state;
        batch.set((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_ID, id), header);
        batch.set((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_HEIGHT, heightBuf), id);
        if (transactions.length > 0) {
            const ids = [];
            for (const { id: txID, value } of transactions) {
                ids.push(txID);
                batch.set((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TRANSACTIONS_ID, txID), value);
            }
            batch.set((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TRANSACTIONS_BLOCK_ID, id), Buffer.concat(ids));
        }
        if (events.length > 0) {
            const encodedEvents = (0, exports.encodeByteArray)(events);
            batch.set((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCK_EVENTS, heightBuf), encodedEvents);
        }
        if (assets.length > 0) {
            const encodedAsset = (0, exports.encodeByteArray)(assets);
            batch.set((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCK_ASSETS_BLOCK_ID, id), encodedAsset);
        }
        if (removeFromTemp) {
            batch.del((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TEMPBLOCKS_HEIGHT, heightBuf));
        }
        const encodedDiff = codec_1.codec.encode(schema_1.stateDiffSchema, diff);
        batch.set((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_DIFF_STATE, (0, utils_1.uint32BE)(height)), encodedDiff);
        const finalizedHeightBytes = Buffer.alloc(4);
        finalizedHeightBytes.writeUInt32BE(finalizedHeight, 0);
        batch.set(db_keys_1.DB_KEY_FINALIZED_HEIGHT, finalizedHeightBytes);
        await this._db.write(batch);
        await this._cleanUntil(height, finalizedHeight);
    }
    async deleteBlock(id, height, txIDs, assets, fullBlock, state, saveToTemp = false) {
        const { batch } = state;
        const heightBuf = (0, utils_1.uint32BE)(height);
        batch.del((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_ID, id));
        batch.del((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCKS_HEIGHT, heightBuf));
        if (txIDs.length > 0) {
            for (const txID of txIDs) {
                batch.del((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TRANSACTIONS_ID, txID));
            }
            batch.del((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TRANSACTIONS_BLOCK_ID, id));
        }
        batch.del((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCK_EVENTS, heightBuf));
        batch.del((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_INCLUSION_PROOFS, heightBuf));
        if (assets.length > 0) {
            batch.del((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCK_ASSETS_BLOCK_ID, id));
        }
        if (saveToTemp) {
            batch.set((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TEMPBLOCKS_HEIGHT, heightBuf), fullBlock);
        }
        const diffKey = (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_DIFF_STATE, heightBuf);
        const stateDiff = await this._db.get(diffKey);
        const { created: createdStates, updated: updatedStates, deleted: deletedStates, } = codec_1.codec.decode(schema_1.stateDiffSchema, stateDiff);
        for (const key of createdStates) {
            batch.del(key);
        }
        for (const { key, value: previousValue } of deletedStates) {
            batch.set(key, previousValue);
        }
        for (const { key, value: previousValue } of updatedStates) {
            batch.set(key, previousValue);
        }
        batch.del(diffKey);
        await this._db.write(batch);
        return {
            deleted: deletedStates,
            created: createdStates,
            updated: updatedStates,
        };
    }
    async _cleanUntil(currentHeight, finalizedHeight) {
        if (finalizedHeight > 0) {
            await this._clear((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_DIFF_STATE, (0, utils_1.uint32BE)(0)), (0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_DIFF_STATE, (0, utils_1.uint32BE)(finalizedHeight - 1)));
        }
        if (this._keepEventsForHeights > -1) {
            const minEventDeleteHeight = Math.min(finalizedHeight, Math.max(0, currentHeight - this._keepEventsForHeights));
            if (minEventDeleteHeight > 0) {
                const endHeight = Buffer.alloc(4);
                endHeight.writeUInt32BE(minEventDeleteHeight - 1, 0);
                await this._clear(Buffer.concat([db_keys_1.DB_KEY_BLOCK_EVENTS, Buffer.alloc(4, 0)]), Buffer.concat([db_keys_1.DB_KEY_BLOCK_EVENTS, endHeight]));
            }
        }
        if (this._keepInclusionProofsForHeights > -1) {
            const minInclusionProofDeleteHeight = Math.min(finalizedHeight, Math.max(0, currentHeight - this._keepInclusionProofsForHeights));
            if (minInclusionProofDeleteHeight > 0) {
                const endHeight = Buffer.alloc(4);
                endHeight.writeUInt32BE(minInclusionProofDeleteHeight - 1, 0);
                await this._clear(Buffer.concat([db_keys_1.DB_KEY_INCLUSION_PROOFS, Buffer.alloc(4, 0)]), Buffer.concat([db_keys_1.DB_KEY_INCLUSION_PROOFS, endHeight]));
            }
        }
    }
    async _getBlockAssets(blockID) {
        try {
            const encodedAssets = await this._db.get((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_BLOCK_ASSETS_BLOCK_ID, blockID));
            return decodeByteArray(encodedAssets);
        }
        catch (error) {
            if (!(error instanceof lisk_db_1.NotFoundError)) {
                throw error;
            }
            return [];
        }
    }
    async _getTransactions(blockID) {
        const txIDs = [];
        try {
            const ids = await this._db.get((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TRANSACTIONS_BLOCK_ID, blockID));
            const idLength = 32;
            for (let i = 0; i < ids.length; i += idLength) {
                txIDs.push(ids.subarray(i, i + idLength));
            }
        }
        catch (error) {
            if (!(error instanceof lisk_db_1.NotFoundError)) {
                throw error;
            }
        }
        if (txIDs.length === 0) {
            return [];
        }
        const transactions = [];
        for (const txID of txIDs) {
            const tx = await this._db.get((0, utils_1.concatDBKeys)(db_keys_1.DB_KEY_TRANSACTIONS_ID, txID));
            transactions.push(tx);
        }
        return transactions;
    }
    async _clear(gte, lte) {
        const stream = this._db.createReadStream({
            gte,
            lte,
        });
        const batch = new lisk_db_1.Batch();
        await new Promise((resolve, reject) => {
            const ids = [];
            stream
                .on('data', ({ key }) => {
                batch.del(key);
            })
                .on('error', error => {
                reject(error);
            })
                .on('end', () => {
                resolve(ids);
            });
        });
        await this._db.write(batch);
    }
}
exports.Storage = Storage;
//# sourceMappingURL=storage.js.map